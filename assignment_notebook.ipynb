{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e649671-64ae-4692-a381-33974ffa666a",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "## Econ 8310 - Business Forecasting\n",
    "\n",
    "For homework assignment 3, you will work with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), a more fancier data set.\n",
    "\n",
    "- You must create a custom data loader as described in the first week of neural network lectures [2 points]\n",
    "    - You will NOT receive credit for this if you use the pytorch prebuilt loader for Fashion MNIST!\n",
    "- You must create a working and trained neural network using only pytorch [2 points]\n",
    "- You must store your weights and create an import script so that I can evaluate your model without training it [2 points]\n",
    "\n",
    "Highest accuracy score gets some extra credit!\n",
    "\n",
    "Submit your forked repository URL on Canvas! :) I'll be manually grading this assignment.\n",
    "\n",
    "Some checks you can make on your own:\n",
    "- Did you manually process the data or use a prebuilt loader (see above)?\n",
    "- Does your script train a neural network on the assigned data?\n",
    "- Did your script save your model?\n",
    "- Do you have separate code to import your model for use after training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      " Starting Training...\n",
      "\n",
      "Epoch 1: Accuracy = 88.10%\n",
      " Saved best model with accuracy: 88.10%\n",
      "Epoch 2: Accuracy = 88.89%\n",
      " Saved best model with accuracy: 88.89%\n",
      "Epoch 3: Accuracy = 90.20%\n",
      " Saved best model with accuracy: 90.20%\n",
      "Epoch 4: Accuracy = 90.52%\n",
      " Saved best model with accuracy: 90.52%\n",
      "Epoch 5: Accuracy = 90.97%\n",
      " Saved best model with accuracy: 90.97%\n",
      "Epoch 6: Accuracy = 91.95%\n",
      " Saved best model with accuracy: 91.95%\n",
      "Epoch 7: Accuracy = 91.72%\n",
      "Epoch 8: Accuracy = 92.17%\n",
      " Saved best model with accuracy: 92.17%\n",
      "Epoch 9: Accuracy = 92.01%\n",
      "Epoch 10: Accuracy = 92.24%\n",
      " Saved best model with accuracy: 92.24%\n",
      "\n",
      " Evaluating Trained Model...\n",
      "\n",
      "\n",
      " Loaded model from best_model.pt\n",
      "Final Evaluation Accuracy: 92.24%\n",
      "\n",
      "Sample Predictions:\n",
      "Sample 1: Predicted = 9, Actual = 9\n",
      "Sample 2: Predicted = 2, Actual = 2\n",
      "Sample 3: Predicted = 1, Actual = 1\n",
      "Sample 4: Predicted = 1, Actual = 1\n",
      "Sample 5: Predicted = 6, Actual = 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os, gzip\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# next,loading the Dataset URLs \n",
    "TRAIN_IMAGES_URL = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz'\n",
    "TRAIN_LABELS_URL = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz'\n",
    "TEST_IMAGES_URL = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'\n",
    "TEST_LABELS_URL = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "# defining the Download Function \n",
    "def download_data(directory=\"./data\"):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    for url in [TRAIN_IMAGES_URL, TRAIN_LABELS_URL, TEST_IMAGES_URL, TEST_LABELS_URL]:\n",
    "        filename = os.path.join(directory, url.split('/')[-1])\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urlretrieve(url, filename)\n",
    "\n",
    "#  attaching the IDX File Loader \n",
    "def load_data(directory=\"./data\", train=True):\n",
    "    if train:\n",
    "        img_path = os.path.join(directory, 'train-images-idx3-ubyte.gz')\n",
    "        lbl_path = os.path.join(directory, 'train-labels-idx1-ubyte.gz')\n",
    "    else:\n",
    "        img_path = os.path.join(directory, 't10k-images-idx3-ubyte.gz')\n",
    "        lbl_path = os.path.join(directory, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    with gzip.open(img_path, 'rb') as img_f:\n",
    "        images = np.frombuffer(img_f.read(), np.uint8, offset=16).reshape(-1, 28, 28)\n",
    "\n",
    "    with gzip.open(lbl_path, 'rb') as lbl_f:\n",
    "        labels = np.frombuffer(lbl_f.read(), np.uint8, offset=8)\n",
    "\n",
    "    return images.astype(np.float32) / 255.0, labels\n",
    "\n",
    "# Custom Dataset Class \n",
    "class MyFashionDataset(Dataset):\n",
    "    def __init__(self, root=\"./data\", train=True):\n",
    "        download_data(root)\n",
    "        self.images, self.labels = load_data(root, train)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.images[idx]).unsqueeze(0)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# intializing the CNN Model \n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Training the model and Evaluation Functions \n",
    "def train_model(model, train_loader, test_loader, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_acc = 0\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Model Evaluation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}: Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': accuracy,\n",
    "                'epoch': epoch\n",
    "            }, \"best_model.pt\")\n",
    "            print(f\" Saved best model with accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "def evaluate_model(model_path=\"best_model.pt\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNNClassifier().to(device)\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "\n",
    "        test_dataset = MyFashionDataset(train=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"\\n Loaded model from {model_path}\")\n",
    "        print(f\"Final Evaluation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # Show sample predictions\n",
    "        print(\"\\nSample Predictions:\")\n",
    "        for i in range(5):\n",
    "            image, label = test_dataset[i]\n",
    "            img_input = image.unsqueeze(0).to(device)\n",
    "            pred = model(img_input).argmax(1).item()\n",
    "            print(f\"Sample {i+1}: Predicted = {pred}, Actual = {label}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\" Model file '{model_path}' not found.\")\n",
    "\n",
    "# Starting the Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    train_dataset = MyFashionDataset(train=True)\n",
    "    test_dataset = MyFashionDataset(train=False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = CNNClassifier().to(device)\n",
    "    print(\"\\n Starting Training...\\n\")\n",
    "    train_model(model, train_loader, test_loader, device)\n",
    "\n",
    "    print(\"\\n Evaluating Trained Model...\\n\")\n",
    "    evaluate_model(\"best_model.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
